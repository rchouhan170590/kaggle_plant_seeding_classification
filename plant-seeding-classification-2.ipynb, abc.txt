{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/plant-seedlings-classification/train/Scentless Mayweed/4ae939d7d.png'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-08T16:54:41.000720Z","iopub.execute_input":"2022-06-08T16:54:41.002020Z","iopub.status.idle":"2022-06-08T16:54:41.011149Z","shell.execute_reply.started":"2022-06-08T16:54:41.001971Z","shell.execute_reply":"2022-06-08T16:54:41.010001Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n# import pandas_profiling\nimport os\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport random\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nimport torchvision.transforms as transforms\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:54:46.292565Z","iopub.execute_input":"2022-06-08T16:54:46.293320Z","iopub.status.idle":"2022-06-08T16:54:47.533207Z","shell.execute_reply.started":"2022-06-08T16:54:46.293280Z","shell.execute_reply":"2022-06-08T16:54:47.531960Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"pil_to_tensor = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5))])\ntensor_to_pil = transforms.Compose([transforms.ToPILImage()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tmp_image = Image.open(\"/kaggle/input/plant-seedlings-classification/train/Scentless Mayweed/4ae939d7d.png\")\nscale_tmp_image = tmp_image.resize((200, 200))\nnumpy_tmp_image = np.array(scale_tmp_image)\nplt.imshow(numpy_tmp_image)\nplt.show()\nnumpy_tmp_image.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"c1 = nn.Conv2d(3, 3, kernel_size=2, stride=1)\nc1_output = c1(pil_to_tensor(scale_tmp_image))","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:54:53.892506Z","iopub.execute_input":"2022-06-08T16:54:53.893148Z","iopub.status.idle":"2022-06-08T16:54:54.026994Z","shell.execute_reply.started":"2022-06-08T16:54:53.893105Z","shell.execute_reply":"2022-06-08T16:54:54.025589Z"},"trusted":true},"execution_count":4,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_969/3414106627.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc1_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpil_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale_tmp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'pil_to_tensor' is not defined"],"ename":"NameError","evalue":"name 'pil_to_tensor' is not defined","output_type":"error"}]},{"cell_type":"code","source":"print(c1_output.shape)\ntensor_to_pil(c1_output)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_dir = '/kaggle/input/plant-seedlings-classification/train'\ntest_data_dir = '/kaggle/input/plant-seedlings-classification/test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_image_path(img_path):\n    img = Image.open(img_path)\n    img_np_array = np.array(img)\n    plt.imshow(img_np_array)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MapLabelToINT:\n    def __init__(self, labels_list):\n        self.labels_list = labels_list\n        self.labels_map = {}\n        for i in range(len(labels_list)):\n            self.labels_map[labels_list[i]] = i\n    \n    def get_id(self, label):\n        return self.labels_map[label]\n    \n    def get_class(self, class_id):\n        for key, val in self.labels_map:\n            if val==class_id:\n                return key\n        return None\n    \n\n    \nlabel_names = os.listdir(train_data_dir)\nprint(label_names)\n\nlabel_mapper = MapLabelToINT(label_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 70% data will be training data and 30% will be the test data\n# here we will use this ratio for each class\nvalidation_ratio = 0.3\n\ntrain_data = []\nvalidation_data = []\n\nfor class_name in label_names:\n    class_path = os.path.join(train_data_dir, class_name)\n    all_files =  [os.path.join(class_path, filename) for filename in os.listdir(class_path)]\n    \n    train, validation = train_test_split(all_files, shuffle=True, test_size=validation_ratio)\n    \n    for t_file in train:\n        train_data.append([t_file, class_name])\n    for v_file in validation:\n        validation_data.append([v_file, class_name])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_data), len(validation_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LabeledDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.data = data\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        img_path, c = self.data[index]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n                \n        return img, c       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pil_data_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),\n#     transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ntensor_to_pil = transforms.Compose([\n    transforms.ToPILImage()\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = LabeledDataset(train_data, pil_data_transforms)\n\nimg, c = train_data_loader.__getitem__(0)\n\npil_mg = tensor_to_pil(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(pil_mg)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_image_path(train_data[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_loader = LabeledDataset(train_data, pil_data_transforms)\nvalidation_data_loader = LabeledDataset(validation_data, pil_data_transforms)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(train_data_loader, shuffle=True, batch_size=8, num_workers=8) \nvalidation_loader = DataLoader(validation_data_loader, shuffle=True, batch_size=8, num_workers=8) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.hub.load('pytorch/vision:v0.10.0', 'squeezenet1_0', pretrained=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_function = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n\n# https://pytorch.org/hub/pytorch_vision_squeezenet/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_tensor_from_labels(labels, label_mapper):\n    label_tensor = torch.zeros((len(labels), 12))\n    \n    for i in range(len(labels)):\n        label_tensor[i][label_mapper.get_id(labels[i])] = 1.0\n    return label_tensor\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.zeros((2,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NewModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.c1 = nn.Linear(1000, 12)\n        self.c2 = nn.Softmax(dim=1)\n    \n    def forward(self, x):\n        out1 = F.relu( self.c1(x))\n        out2 = self.c2(out1)\n        \n        return out2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoches = 10\n\n\nnew_layer = NewModel()\nmodel.train()\nnew_layer.train()\nfor params in model.parameters():\n    params.requires_grad = False\n\n\nfor epoch in range(epoches):\n    running_loss = 0.0\n    for i, data in enumerate(iter(train_loader), 0):\n        inputs, labels = data\n        \n        label_tensor = get_tensor_from_labels(labels, label_mapper)\n        optimizer.zero_grad()\n        \n        _outputs = model(inputs)\n        outputs = new_layer(_outputs)\n        loss = loss_function(outputs, label_tensor)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        if i % 50 == 49:\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 50))\n            running_loss = 0.0\n    \n    scheduler.step()\n\nprint('Finished Training')","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\n\ndef save_model(model, filename):\n    base_path = \"/kaggle/model/\"\n    os.makedirs(base_path, exist_ok=True)\n    file_path = os.path.join(base_path, filename)\n    pickle.dump(model, open(file_path, 'wb'))\n    \n    \n    \ndef load_model(filename):\n    base_path = \"/kaggle/model/\"\n    file_path = os.path.join(base_path, filename)\n    loaded_model = pickle.load(open(file_path, 'rb'))\n    \n    return loaded_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"model_v2_linear_softmax.sav\"\n\nsave_model(new_layer, filename)\n# new_layer = load_model(filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\nnew_layer.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nn.Softmax()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correct = 0\nno_correct = 0\nwith torch.no_grad():\n    for imgs, labels in validation_loader:\n        _pred = model(imgs)\n        output = new_layer(_pred)\n        for i in range(len(labels)):\n            pred = torch.argmax(output[i])\n            if pred == label_mapper.get_id(labels[i]):\n                correct += 1\n            else:\n                no_correct += 1\n        ","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(validation_loader)\nimages, labels = dataiter.next()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_out = model(images)\nout = new_layer(_out)\n\nprint(out.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.argmax(out[0]), label_mapper.get_id(labels[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(correct, no_correct)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_mapper.get_id(labels[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = model(imgs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2022-06-08T16:55:23.636215Z","iopub.execute_input":"2022-06-08T16:55:23.637100Z","iopub.status.idle":"2022-06-08T16:55:24.439041Z","shell.execute_reply.started":"2022-06-08T16:55:23.637037Z","shell.execute_reply":"2022-06-08T16:55:24.437702Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  abc.txt  kaggle_plant_seeding_classification\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-08T15:57:57.180954Z","iopub.execute_input":"2022-06-08T15:57:57.181356Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}